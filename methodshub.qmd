---
format:
  html:
    embed-resources: true
  gfm: default
---

# webtrackR - Preprocessing and Analyzing Web Tracking Data
<!--
General specifications:
- This specification of the Methods Hub friendly README often uses the word 'should' to indicate the usual case. If you feel you need to do it differently, add a comment to argue for your case when you submit your method.
- A Methods Hub friendly README should contain all sections below that are not marked as optional, and can contain more sections.
- A Methods Hub friendly README should contain as few technical terms as possible and explain (or link to an explanation of) all used technical terms.
- A Methods Hub friendly README should link to all code files that it mentions using the [text](URL relative to this file) format. The relative URL (i.e., no "https://github.com") is neccessary for proper versioning in Methods Hub.
- A Methods Hub friendly README should contain an explanation (in the text) and an alternative for each image it contains (e.g., data models, pipeline, schema structure). Format: ![alternative text that describes what is visible in the image](URL relative to this file).
- A Methods Hub friendly README should link to authoritative sources rather than containing a copy of the information (e.g., documentation).
- A Methods Hub friendly README should use a uniform citation style for all references, for example APA7 https://apastyle.apa.org/style-grammar-guidelines/references/examples

Title:
1. The title must be the README's only first-level heading (line starting with a single '#').
2. The title should make the method's purpose clear.
3. The title (line 1 of this file) must be changed by you, but all other headings should be kept as they are.
4. The title must be appropriate (not harmful, derogatory, etc.).

Section templates:
The README template comes with text templates for each section (after each comment) that can be used, customized or removed as desired.
-->

## Description
<!--
1. Provide a brief and exact description of the method clearly mentioning its purpose i.e., what the method does or aims to achieve in abstract terms (avoiding technical details).
2. The focus should be on explaining the method in a way that helps users with different levels of expertise understand what it does, without going into technical details. It should clearly describe what inputs are needed and what outputs can be expected.
3. Briefly explain the input and output of the method and its note worthy features.
4. Provide link(s) to related papers from the social science domain using the method or similar methods for solving social science research questions. 
5. In a separate paragraph, highlight the reproducibility aspect of the method providing details or references to the resources used by the method, the data used in building the pre-trained modules etc.
6. It should also discuss the decisions and parameters controlling the behavior of the method.
-->

The package offers data structures and methods to work with web tracking data. The functions cover data preprocessing steps, enriching web tracking data with external information and methods for the analysis of digital behavior as used in several academic papers (e.g., Clemm von Hohenberg et al., 2023 [doi:10.17605/OSF.IO/M3U9P](https://doi.org/10.17605/OSF.IO/M3U9P); Stier et al., 2022 [doi:10.1017/S0003055421001222](https://doi.org/10.1017/S0003055421001222)).

## Keywords

<!-- EDITME -->

* Digital Behavioral Data 
* Webtracking
* Data Preprocessing

## Use Cases
<!--
1. The use cases section should contain a list of use cases relevant to the social sciences.
2. Each use case should start with a description of a task and then detail how one can use the method to assist in the task.
3. Each use case may list publications in which the use case occurs (e.g., in APA7 style, https://apastyle.apa.org/style-grammar-guidelines/references/examples).
-->

Web tracking data provides a powerful tool for social science research, enabling the analysis of human behavior and interaction patterns in digital environments. By capturing detailed user activity, such as page visits, clickstreams, and time spent on various platforms, researchers can uncover insights into online decision-making, information diffusion, and social influence. This data can also be used to study phenomena like polarization or the impact of targeted advertising on public opinion. 

## Input Data
<!--
1. The input data section should illustrate the input data format by showing a (possibly abbreviated) example item and explaining (or linking to an explanation of) the data fields.
2. The input data section should specify which parts of the input data are optional and what effect it has to not provide these.
3. The input data section should link to a small example input file in the same repository that can be used to test the method (this test should be described in the section "How to Use").
-->

`webtrackR` accepts raw webtracking data as provided by GESIS and includes a sample dataset of raw webtracking data. 

## Output Data
<!--
1. The output data section should illustrate the output data format by showing a (possibly abbreviated) example item and explaining (or linking to an explanation of) the data fields.
2. The output data section should link to a small example output file in the same repository that can be re-created (as far as the method is non-random) from the input data (as described in the section "How to Use").
-->

The functions in webtrackR return processed `wt_dt` objects (enhanced data frames) that contain enriched, cleaned, or summarized web tracking data. These objects remain in-memory within R and can be directly analyzed, visualized, or explicitly exported by the user into external file formats such as CSV or RDS.

```{r}
#| eval: false
# Example: export a processed webtrackR object to CSV
write.csv(my_wt_data, "processed_webtracking.csv", row.names = FALSE)
```

## Environment Setup
<!--
1. The environment setup section should list all requirements and provide all further steps to prepare an environment for running the method (installing requirements, downloading files, creating directoriees, etc.).
2. The environment setup section should recommend to use a virtual environment or similar if the programming language supports one.
-->

With R installed:

```r
install.packages("webtrackR")
```

## How to Use
<!--
1. The how to use section should provide the list of steps that are necessary to produce the example output file (see section Output Data) after having set up the environment (see section Environment Setup).
2. The how to use section should explain how to customize the steps to one's own needs, usually through configuration files or command line parameters, or refer to the appropriate open documentation.
-->

The **webtrackR** package is designed to preprocess, classify, and analyze web tracking data (web browsing histories of participants in academic studies). A typical workflow combines preprocessing of raw tracking data, enrichment with additional information, classification of visits, and aggregation or summarization for further analysis.  

### Prepare your raw data

Raw web tracking data must contain at least the following variables:  

- `panelist_id`: the identifier of the participant from whom the data was collected  
- `url`: the visited URL  
- `timestamp`: the time of the visit  

After loading the data into R, use the function `as.wt_dt()` to convert it into the special `wt_dt` format. This assigns the correct class, ensures that required variables are present, and converts the timestamp into `POSIXct` format. All subsequent functions in the package check for these variables and will throw an error if they are missing.

### Preprocess the data

Several functions can be used to derive new variables and enrich the raw data:  

- `add_duration()`: calculates the time spent on a visit by measuring the difference between subsequent timestamps, with options to handle unusually long gaps using the `cutoff` and `replace_by` arguments.  
- `add_session()`: groups subsequent visits into browsing sessions, stopping when the gap between visits exceeds a specified `cutoff`.  
- `extract_host()`, `extract_domain()`, and `extract_path()`: parse URLs into host, domain, and path components.  
- `drop_query()`: removes query strings or fragments from URLs.  
- `add_next_visit()` and `add_previous_visit()`: add the following or preceding URL, domain, or host as a new variable.  
- `add_referral()`: flags whether a visit was referred by a social media platform (based on Schmidt et al., 2023).  
- `add_title()`: retrieves the `<title>` text of the visited webpage and adds it as a variable.  
- `add_panelist_data()`: joins web tracking data with additional participant information such as survey data.  

### Classify visits

To categorize website visits, use `classify_visits()`. Visits can be matched by extracting the domain or host and comparing them to a predefined list, or by applying regular expressions to the raw URL. This step is essential if you want to distinguish between classes of sites (e.g., news, social media, search engines).  

### Summarize and aggregate

Once the data has been preprocessed and classified, it can be aggregated for analysis:  

- `deduplicate()`: flags, drops, or aggregates consecutive visits to the same URL within a given time window.  
- `sum_visits()`: counts visits by participant and timeframe (e.g., day, week, or date), optionally by a visit class.  
- `sum_durations()`: aggregates total visit durations across timeframes or classes.  
- `sum_activity()`: counts the number of active periods (e.g., active days) per participant.  

### Work with the results

All functions return updated `wt_dt` objects, which are simply enhanced data frames. These objects remain in memory in R and can be directly inspected, analyzed, or visualized.  

By default, **webtrackR does not create output files**. If you wish to save the processed or summarized data, you must export it explicitly. For example:  

```{r}
library("webtrackR")

# load example data and turn it into wt_dt
data("testdt_tracking")
my_wt_data <-as.wt_dt(testdt_tracking)

# output the data as a csv
write.csv(my_wt_data, "processed_webtracking.csv", row.names = FALSE)
```

### Customize the workflow

The workflow is highly customizable through function arguments:  

- Adjust `cutoff` values in `add_duration()` or `add_session()` to change how long gaps between visits are handled.  
- Specify `within` and `method` in `deduplicate()` to control how duplicates are flagged, dropped, or aggregated.  
- Set `timeframe` in `sum_visits()` or `sum_durations()` to change the level of aggregation (e.g., daily, weekly).  
- Provide your own domain lists or regular expressions in `classify_visits()` to match visits to custom categories.  

### Example Code

A typical workflow including preprocessing, classifying and aggregating web tracking data looks like this (using the available example data):  

```{r}
#| warning: false
# load example data and turn it into wt_dt
data("testdt_tracking")
wt <- as.wt_dt(testdt_tracking)

# add duration
wt <- add_duration(wt)

# extract domains
wt <- extract_domain(wt)

# drop duplicates (consecutive visits to the same URL within one second)
wt <- deduplicate(wt, within = 1, method = "drop")

# load example domain classification and classify domains
data("domain_list")
wt <- classify_visits(wt, classes = domain_list, match_by = "domain")

# load example survey data and join with web tracking data
data("testdt_survey_w")
wt <- add_panelist_data(wt, testdt_survey_w)

# aggregate number of visits by day and panelist, and by domain class
wt_summ <- sum_visits(wt, timeframe = "date", visit_class = "type")
```

## Technical Details
<!--
1. The technical details section should proview a process overview, linking to key source code files at every step of the process.
2. In case a publication provides the details mentioned below, the technical details section should link to this publication using a sentence like "See the [publication](url-of-publication-best-using-doi) for ...". In this case, the mentioned technical details can be omitted from the section.
3. The technical details section should list all information needed to reproduce the method, including employed other methods and selected parameters.
4. The input data section should link to external data it uses, preferably using a DOI to a dataset page or to API documentation.
5. The technical details section should mention how other methods and their parameters were selected and which alternatives were tried.
6. The technical details section should for employed machine learning models mention on what kind of data they were trained.
-->

See the official [CRAN page](https://doi.org/10.32614/CRAN.package.webtrackR) for further information about technical details.

<!--## References -->
<!--
1. The references section is optional, especially if they are cited in a publication that explains the technical details (see section Technical Details).
2. The references section should provide references of publications related to this method (e.g., in APA7 style, https://apastyle.apa.org/style-grammar-guidelines/references/examples).
-->

<!-- ## Acknowledgements -->
<!--
1. The acknowledgments section is optional.
2. The acknowledgments section should list expressions of gratitude to people or organizations who contributed, supported or guided.
-->

<!-- ## Disclaimer-->
<!--
1. The disclaimer section is optional.
2. The disclaimer section should list disclaimers, legal notices, or usage restrictions for the method.
-->

## Contact Details
<!-- 
1. The contact details section should specify whom to contact for questions or contributions and how (can be separate entitites; for example email addresses or links to the GitHub issue board).
-->

Maintainer: David Schoch <david@schochastics.net>

Issue Tracker: [https://github.com/gesistsa/webtrackR/issues](https://github.com/gesistsa/webtrackR/issues)
